{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4360b494-f1fb-44f0-8f13-2f29b93b91e7",
   "metadata": {},
   "source": [
    "# Old unused code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e58c74-dd05-42cd-9843-4389b7fca68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gis.stackexchange.com/questions/250172/finding-out-if-coordinate-is-within-shapefile-shp-using-pyshp\n",
    "# transforming x/y_coord_cd to zip code\n",
    "# there were two cases where this didn't work and i manually inputted the zip code by looking up\n",
    "# https://lookups.melissa.com/home/latlngzip4/\n",
    "import shapefile\n",
    "from shapely.geometry import Point, shape\n",
    "shp = shapefile.Reader('zip_boundaries/ZIP_CODE_040114.shp')\n",
    "all_shapes = [shape(i) for i in shp.shapes()]\n",
    "all_records = shp.records()\n",
    "def get_zip(row):\n",
    "  to_check = Point(row.X_COORD_CD, row.Y_COORD_CD)\n",
    "  return [all_records[i][0] for i in range(len(all_shapes)) if all_shapes[i].contains(to_check)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc8ddc7-d9ac-400f-a4ea-be208e76ded3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge sales data\n",
    "import os\n",
    "import pandas as pd\n",
    "data_file_folder = 'Rolling_Data_Sales'\n",
    "\n",
    "dfs = []\n",
    "for file in os.listdir(data_file_folder):\n",
    "    print('Loading file {0}...'.format(file))\n",
    "    header_lines = 4 if int(file[:4]) < 2020 else 6\n",
    "    newdf = pd.read_excel(os.path.join(data_file_folder, file), header=header_lines)\n",
    "    newdf.rename(lambda x: (x[:-1] if x.endswith(\"\\n\") else x).replace(\"\\n\", \" \").replace(\"  \", \" \"), axis='columns', inplace=True)\n",
    "    dfs.append(newdf)\n",
    "df = pd.concat(dfs)\n",
    "df.to_csv(\"all_sales.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a4cc8038-ada4-4049-9797-0d2137aa4f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# load street endings\n",
    "stypes = pd.read_csv(\"street types.csv\")\n",
    "stypes.fillna(method=\"ffill\", inplace=True)\n",
    "stypes.drop(columns=[\"Primary Street Suffix Name\"], inplace=True)\n",
    "stypes.rename({\n",
    "    \"Commonly Used Street Suffix or Abbreviation\": \"name\",\n",
    "    \"Postal Service Standard Suffix Abbreviation\": \"abbr\"\n",
    "}, axis=\"columns\", inplace=True)\n",
    "stypes.set_index(\"name\", inplace=True)\n",
    "abbr_map = stypes.to_dict(\"index\")\n",
    "\n",
    "dir_map = {\n",
    "    \"NORTH\": \"N\",\n",
    "    \"SOUTH\": \"S\",\n",
    "    \"EAST\": \"E\",\n",
    "    \"WEST\": \"W\"\n",
    "}\n",
    "\n",
    "def memoize(f):\n",
    "    memo = {}\n",
    "    def helper(x):\n",
    "        if x not in memo:            \n",
    "            memo[x] = f(x)\n",
    "        return memo[x]\n",
    "    return helper\n",
    "\n",
    "@memoize\n",
    "def standardizeAddress(address):\n",
    "    # normalize\n",
    "    out = address.strip().upper().split(\",\")[0]\n",
    "    \n",
    "    # tokenize and do things\n",
    "    tokens = out.split(\" \")\n",
    "    # convert street names\n",
    "    last = tokens[-1]\n",
    "    if last in abbr_map:\n",
    "        tokens[-1] = abbr_map[last][\"abbr\"]\n",
    "    # convert convert east/west/north/south to ewns and get rid of extra space\n",
    "    tokens = [dir_map.get(token, token) for token in tokens if token != \"\"]\n",
    "    # convert numbers ie 1st -> 1\n",
    "    if len(tokens) >= 3:\n",
    "        stnum = tokens[-2]\n",
    "        tokens[-2] = re.sub(\"^(\\d+).*$\", lambda x: x.group(1), stnum)\n",
    "    \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6fd0b641-6361-4ae2-9c56-6784328ccb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# normalizing addresses\n",
    "import pandas as pd\n",
    "# import requests, json, pandas as pd\n",
    "# API_KEY = \"AIzaSyAlW2MtnVvDCFYdhxqjdNgbZ0jEWdoovy8\"\n",
    "# with open(\"progress.out\", \"w\") as f:\n",
    "#     f.write(\"\")\n",
    "# def memoize(f):\n",
    "#     memo = {}\n",
    "#     def helper(x):\n",
    "#         if x not in memo:            \n",
    "#             memo[x] = f(x)\n",
    "#         return memo[x]\n",
    "#     return helper\n",
    "\n",
    "# @memoize\n",
    "# def standardizeAddress(address):\n",
    "#     with open(\"progress.out\", \"a\") as f:\n",
    "#         f.write(\"Converting address:\\t\" + address + \"\\n\")\n",
    "#     data = {\n",
    "#         \"address\": {\n",
    "#             \"regionCode\": \"US\",\n",
    "#             \"locality\": \"New York City\",\n",
    "#             \"addressLines\": [address]\n",
    "#         }\n",
    "#     }\n",
    "#     return json.loads(\n",
    "#         requests.post(\"https://addressvalidation.googleapis.com/v1:validateAddress?key=\" + API_KEY, json=data,).text\n",
    "#     )[\"result\"][\"address\"][\"formattedAddress\"]\n",
    "\n",
    "# example: standardizeAddress(\"276 Pulaski Avenue\")\n",
    "\n",
    "# standardize addresses\n",
    "cols = {\n",
    "    \"BOROUGH\": \"int32\",\n",
    "    \"ZIP CODE\": \"int32\",\n",
    "    \"YEAR BUILT\": \"int32\",\n",
    "    \"ADDRESS\": \"string\",\n",
    "    \"SALE PRICE\": \"float32\",\n",
    "    \"SALE DATE\": \"string\"\n",
    "}\n",
    "df = pd.read_csv(\"all_sales_cleanedv2.csv\", usecols=cols.keys(), dtype=cols, sep=\";\")\n",
    "df.rename({\"SALE DATE\": \"SALE_DATE\", \"SALE PRICE\": \"SALE_PRICE\"}, axis=\"columns\", inplace=True)\n",
    "df.SALE_DATE = pd.to_datetime(df.SALE_DATE)\n",
    "df[\"STD_ADD\"] = df.apply(lambda row: standardizeAddress(row.ADDRESS), axis=1)\n",
    "df.to_csv(\"with_std_add.csv\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7637024-a51f-4d47-8064-a42dcb9dcc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average apartment price increase per zip code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "progress = {\n",
    "    \"c1\": 0,\n",
    "    \"c2\": 0\n",
    "}\n",
    "\n",
    "# the func to apply to the apartment dataframes to get growth rates\n",
    "def apartment_apply(df):\n",
    "    # progress tracking\n",
    "    progress[\"c1\"] += 1\n",
    "    if progress[\"c1\"] % 20 == 0:\n",
    "        print(\"\\rProgress: %d\" % progress[\"c1\"], end=\"\")\n",
    "    \n",
    "    price_diff = df.price.shift() / df.price\n",
    "    date_diff = (df.sale_date.shift() - df.sale_date).dt.days / 30\n",
    "    growth_rate = price_diff.pow(1 / date_diff) - 1\n",
    "    end_period = df.sale_date.shift().dt.to_period(\"M\").rename(\"end_date\")\n",
    "    start_period = df.sale_date.dt.to_period(\"M\").rename(\"start_date\")\n",
    "    return pd.concat([growth_rate.rename(\"growth_rate\"), start_period, end_period, df.zip_code], axis=1).iloc[1:, :]\n",
    "\n",
    "# expands to have a row per month\n",
    "def gbs_apply(row, growth_rates):\n",
    "    # progress tracking\n",
    "    progress[\"c2\"] += 1\n",
    "    if progress[\"c2\"] % 1 == 0:\n",
    "        print(\"\\rProgress: %d\" % progress[\"c2\"], end=\"\")\n",
    "        \n",
    "    out = pd.DataFrame(index=pd.period_range(row.start_date, row.end_date))\n",
    "    out.index.rename(\"year_month\", inplace=True)\n",
    "    out[\"zip_code\"] = row.zip_code\n",
    "    out.set_index([\"zip_code\"], append=True, inplace=True)\n",
    "    out[\"growth_rate\"] = row.growth_rate\n",
    "    out[\"c\"] = 1\n",
    "    return out\n",
    "    \n",
    "# Create a function to cluster the apartments by zip code and calculate the average price growth of each zip code per month\n",
    "def calculate_zip_code_growth(data):\n",
    "    # Filter only apartments that appeared at least twice in the data\n",
    "    apartment_counts = data['apartment_id'].value_counts()\n",
    "    valid_apartment_ids = apartment_counts[apartment_counts >= 2].index\n",
    "    valid_data = data[data['apartment_id'].isin(valid_apartment_ids)]\n",
    "    \n",
    "    # Calculate the growth rate for each zip per month\n",
    "    growth_rates = pd.DataFrame(columns=[\"year_month\", \"zip_code\", \"growth_rate\", \"c\"])\n",
    "    growth_rates.set_index([\"year_month\", \"zip_code\"], inplace=True)\n",
    "    print(\"Calculating growth rate per sale...\")\n",
    "    print(\"Predicted load: %d\" % len(valid_apartment_ids))\n",
    "    growth_by_sale = valid_data.groupby(\"apartment_id\", group_keys=True).apply(apartment_apply)\n",
    "    print(\"Aggregating growth rates per sale...\")\n",
    "    print(\"Predicted load: %d\" % len(growth_by_sale))\n",
    "    # growth_by_sale_by_month = growth_by_sale.apply(gbs_apply, axis=1, growth_rates=growth_rates)\n",
    "    for index, row in growth_by_sale.iterrows():\n",
    "        progress[\"c2\"] += 1\n",
    "        if progress[\"c2\"] % 1 == 0:\n",
    "            print(\"\\rProgress: %d\" % progress[\"c2\"], end=\"\")\n",
    "\n",
    "        out = pd.DataFrame(index=pd.period_range(row.start_date, row.end_date))\n",
    "        out.index.rename(\"year_month\", inplace=True)\n",
    "        out[\"zip_code\"] = row.zip_code\n",
    "        out.set_index([\"zip_code\"], append=True, inplace=True)\n",
    "        out[\"growth_rate\"] = row.growth_rate\n",
    "        out[\"c\"] = 1\n",
    "        \n",
    "        growth_rates = growth_rates.add(out, fill_value=0)\n",
    "    growth_rates[\"avg_growth_rate\"] = growth_rates[\"growth_rate\"] * 100 / growth_rates[\"c\"]\n",
    "    growth_rates.drop([\"growth_rate\", \"c\"], inplace=True, axis=\"columns\")\n",
    "    \n",
    "    return growth_rates\n",
    "\n",
    "print(\"Program start\")\n",
    "print(\"Reading in file...\")\n",
    "data = pd.read_csv(\"with_std_add.csv\", usecols=['STD_ADD', 'ZIP CODE', 'SALE_DATE', 'SALE_PRICE'])\n",
    "data.rename({'STD_ADD': 'apartment_id', 'ZIP CODE': 'zip_code', 'SALE_DATE': 'sale_date', 'SALE_PRICE': 'price'}, axis=\"columns\", inplace=True)\n",
    "data.sale_date = pd.to_datetime(data.sale_date)\n",
    "data.drop_duplicates(inplace=True)\n",
    "# data = data.iloc[:500, :]\n",
    "data = data[data.price > 100]\n",
    "# Calculate the average price growth of each zip code per month\n",
    "zip_code_growth = calculate_zip_code_growth(data)\n",
    "print(\"done\")\n",
    "zip_code_growth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
